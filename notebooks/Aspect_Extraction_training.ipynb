{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6efdfda3",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d82468bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_extraction.text import  TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb4658c",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18a0503a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_ID</th>\n",
       "      <th>Sentence_ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Token_Text</th>\n",
       "      <th>Opinion_Target</th>\n",
       "      <th>Opinion_Category</th>\n",
       "      <th>Opinion_Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1004293</td>\n",
       "      <td>1004293:0</td>\n",
       "      <td>judging from previous posts this used to be a ...</td>\n",
       "      <td>judging previous post used good place longer</td>\n",
       "      <td>place</td>\n",
       "      <td>RESTAURANT#GENERAL</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1004293</td>\n",
       "      <td>1004293:1</td>\n",
       "      <td>we there were four of us arrived at noon the p...</td>\n",
       "      <td>four arrived noon place empty staff acted like...</td>\n",
       "      <td>staff</td>\n",
       "      <td>SERVICE#GENERAL</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1004293</td>\n",
       "      <td>1004293:2</td>\n",
       "      <td>they never brought us complimentary noodles ig...</td>\n",
       "      <td>never brought complimentary noodle ignored rep...</td>\n",
       "      <td>service</td>\n",
       "      <td>SERVICE#GENERAL</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004293</td>\n",
       "      <td>1004293:3</td>\n",
       "      <td>the food was lousy too sweet or too salty and ...</td>\n",
       "      <td>food lousy sweet salty portion tiny</td>\n",
       "      <td>food</td>\n",
       "      <td>FOOD#QUALITY</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004293</td>\n",
       "      <td>1004293:3</td>\n",
       "      <td>the food was lousy too sweet or too salty and ...</td>\n",
       "      <td>food lousy sweet salty portion tiny</td>\n",
       "      <td>portions</td>\n",
       "      <td>FOOD#STYLE_OPTIONS</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Review_ID Sentence_ID                                               Text  \\\n",
       "0    1004293   1004293:0  judging from previous posts this used to be a ...   \n",
       "1    1004293   1004293:1  we there were four of us arrived at noon the p...   \n",
       "2    1004293   1004293:2  they never brought us complimentary noodles ig...   \n",
       "3    1004293   1004293:3  the food was lousy too sweet or too salty and ...   \n",
       "4    1004293   1004293:3  the food was lousy too sweet or too salty and ...   \n",
       "\n",
       "                                          Token_Text Opinion_Target  \\\n",
       "0       judging previous post used good place longer          place   \n",
       "1  four arrived noon place empty staff acted like...          staff   \n",
       "2  never brought complimentary noodle ignored rep...        service   \n",
       "3                food lousy sweet salty portion tiny           food   \n",
       "4                food lousy sweet salty portion tiny       portions   \n",
       "\n",
       "     Opinion_Category Opinion_Polarity  \n",
       "0  RESTAURANT#GENERAL         negative  \n",
       "1     SERVICE#GENERAL         negative  \n",
       "2     SERVICE#GENERAL         negative  \n",
       "3        FOOD#QUALITY         negative  \n",
       "4  FOOD#STYLE_OPTIONS         negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"datasets/training_dataset/Preprocessed_Restuarant_Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d64529",
   "metadata": {},
   "source": [
    "# Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aff1d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df['Opinion_Target']\n",
    "y_category = df['Opinion_Category']\n",
    "\n",
    "X1_train, X1_test, y_category_train, y_category_test = train_test_split(\n",
    "                                                              X1, y_category, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a494d0",
   "metadata": {},
   "source": [
    "# Vectorization techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "271a2f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of vectorization techniques and their names\n",
    "vectorization_techniques1 = [\n",
    "    (\"TF-IDF\", TfidfVectorizer(max_features=5000, sublinear_tf=True, stop_words='english')),\n",
    "    (\"Count Vectorization (BoW)\", CountVectorizer(max_features=5000, stop_words='english'))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110e8d24",
   "metadata": {},
   "source": [
    "# ML Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e347120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of classifiers\n",
    "classifiers1 = {\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=10, criterion=\"entropy\"),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=0),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(criterion='entropy', random_state=0),\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=50, random_state=0),\n",
    "    \"Bagging\": BaggingClassifier(n_estimators=50, random_state=0),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(n_estimators=50, criterion=\"entropy\", random_state=0),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42da2fd1",
   "metadata": {},
   "source": [
    "# Comparing different classifers with different vectorization techniques to predict Opinion_Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b92d7891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Table:\n",
      "\n",
      "Technique               Count Vectorization (BoW)  TF-IDF\n",
      "Classifier                                               \n",
      "AdaBoost                                   0.6000  0.6000\n",
      "Bagging                                    0.7450  0.7525\n",
      "Decision Tree                              0.7400  0.7450\n",
      "Extra Trees                                0.7525  0.7575\n",
      "Gradient Boosting                          0.7500  0.7575\n",
      "K-Nearest Neighbors                        0.6475  0.7350\n",
      "Logistic Regression                        0.7300  0.7300\n",
      "Naive Bayes                                0.7300  0.7175\n",
      "Random Forest                              0.7550  0.7525\n",
      "Support Vector Machine                     0.7575  0.7600\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = []\n",
    "# Iterate through vectorization techniques and classifiers\n",
    "for technique_name, vectorizer in vectorization_techniques1:\n",
    "    X1_train_vectorized = vectorizer.fit_transform(X1_train)\n",
    "    X1_test_vectorized = vectorizer.transform(X1_test)\n",
    "\n",
    "    for classifier_name, classifier in classifiers1.items():\n",
    "        classifier.fit(X1_train_vectorized, y_category_train)\n",
    "        y_category_pred = classifier.predict(X1_test_vectorized)\n",
    "        category_accuracy = accuracy_score(y_category_test, y_category_pred)\n",
    "\n",
    "        result = {\n",
    "            \"Technique\": technique_name,\n",
    "            \"Classifier\": classifier_name,\n",
    "            \"Accuracy\": category_accuracy\n",
    "        }\n",
    "\n",
    "        results.append(result)\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Pivot the DataFrame to form the result table\n",
    "pivot_table = pd.pivot_table(results_df, values='Accuracy',\n",
    "                                index='Classifier', columns='Technique')\n",
    "\n",
    "# Fill NaN values with a placeholder (e.g., \"N/A\")\n",
    "pivot_table = pivot_table.fillna(\"N/A\")\n",
    "\n",
    "\n",
    "\n",
    "# Display the result table\n",
    "print(\"Results Table:\\n\")\n",
    "print(pivot_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00da8af",
   "metadata": {},
   "source": [
    "# Training  SVM classifier with TF-IDF vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1fc0e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To ignore any warning while runtime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "# warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Text vectorization using TF-IDF\n",
    "tfidf_vectorizer_AE = TfidfVectorizer(max_features=5000, sublinear_tf=True, stop_words='english')\n",
    "X1_train_tfidf = tfidf_vectorizer_AE.fit_transform(X1_train)\n",
    "X1_test_tfidf = tfidf_vectorizer_AE.transform(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfaa97a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training  SVM classifier\n",
    "SVM_opinion_category_classifier = SVC()\n",
    "SVM_opinion_category_classifier.fit(X1_train_tfidf, y_category_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f10ac5",
   "metadata": {},
   "source": [
    "# Save the trained TF-IDF vectorizer and SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd45ab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained TF-IDF vectorizer\n",
    "with open(\"pickle_files/tfidf_vectorizer_AE.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tfidf_vectorizer_AE, f)\n",
    "\n",
    "# Save the trained SVM model\n",
    "with open(\"pickle_files/SVM_opinion_category_classifier.pkl\", \"wb\") as f:\n",
    "    pickle.dump(SVM_opinion_category_classifier, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d3cbb0",
   "metadata": {},
   "source": [
    "# Predicting Opinion Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02ddd8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_category_pred = SVM_opinion_category_classifier.predict(X1_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ea15c7",
   "metadata": {},
   "source": [
    "# Opinion Category Classification Report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e319ab57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opinion Category Accuracy : 0.76\n",
      "\n",
      "Opinion Category Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "        AMBIENCE#GENERAL       0.97      0.64      0.77        44\n",
      "           DRINKS#PRICES       0.00      0.00      0.00         4\n",
      "          DRINKS#QUALITY       0.55      0.60      0.57        10\n",
      "    DRINKS#STYLE_OPTIONS       1.00      0.38      0.55         8\n",
      "             FOOD#PRICES       0.00      0.00      0.00        14\n",
      "            FOOD#QUALITY       0.72      0.99      0.83       136\n",
      "      FOOD#STYLE_OPTIONS       0.56      0.25      0.34        20\n",
      "        LOCATION#GENERAL       1.00      0.80      0.89         5\n",
      "      RESTAURANT#GENERAL       0.65      0.85      0.74        62\n",
      "RESTAURANT#MISCELLANEOUS       0.50      0.07      0.12        14\n",
      "       RESTAURANT#PRICES       0.00      0.00      0.00        10\n",
      "         SERVICE#GENERAL       0.97      0.96      0.97        73\n",
      "\n",
      "                accuracy                           0.76       400\n",
      "               macro avg       0.58      0.46      0.48       400\n",
      "            weighted avg       0.72      0.76      0.72       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy and print classification report\n",
    "category_accuracy = accuracy_score(y_category_test, y_category_pred)\n",
    "category_report = classification_report(y_category_test, y_category_pred)\n",
    "\n",
    "print(f\"Opinion Category Accuracy : {category_accuracy}\")\n",
    "print(\"\\nOpinion Category Classification Report:\")\n",
    "print(category_report)\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
