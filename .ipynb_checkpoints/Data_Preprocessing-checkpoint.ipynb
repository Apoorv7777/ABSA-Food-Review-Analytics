{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8dfe9fd",
   "metadata": {},
   "source": [
    "# DATA PROCEESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cf64ae",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e48a372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import spacy\n",
    "import emoji\n",
    "import os\n",
    "import json\n",
    "from deep_translator import GoogleTranslator\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6081d4",
   "metadata": {},
   "source": [
    "## Load NLTK stopwords and lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006a52f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e3981",
   "metadata": {},
   "source": [
    "## Load spaCy model for lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565bb689",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20018b5",
   "metadata": {},
   "source": [
    "## Set the option to display full column width and all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece56aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\",None)\n",
    "pd.set_option(\"display.max_rows\",None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b3c070",
   "metadata": {},
   "source": [
    "# Load your ABSA dataset\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e514c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"training_dataset/Restaurant_Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be7140a",
   "metadata": {},
   "source": [
    "### Load database information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75f069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcecedfb",
   "metadata": {},
   "source": [
    "### Finding number of missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d9cdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bbb1ed",
   "metadata": {},
   "source": [
    "### Handling missing values of Opinion_Target Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7275f691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_value_handler(df):\n",
    "    return df['Opinion_Category'].split('#')[0].lower() if pd.isna(df['Opinion_Target']) else df['Opinion_Target']\n",
    "\n",
    "df['Opinion_Target'] = df.apply(missing_value_handler, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c80976d",
   "metadata": {},
   "source": [
    "### Checking number of missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf03a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cfbb71",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166d3c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove special characters and punctuation\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5425e7f1",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27a3808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d018652",
   "metadata": {},
   "source": [
    "### Rejoins the tokens to form the sentence back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029f04ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_tokens(tokens):\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7a5f41",
   "metadata": {},
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ca0bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens):\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dbcd07",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872335ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(tokens):\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96213c6",
   "metadata": {},
   "source": [
    "### Removes the word with length less than or equal to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b17c0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def short_remover(tokens):\n",
    "    new_tokens = [word for word in tokens if len(word) > 2 ]\n",
    "    return new_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4164b1a2",
   "metadata": {},
   "source": [
    "## Translate text into English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eac5b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text):\n",
    "    translator = GoogleTranslator(source='auto', target='en')\n",
    "    return translator.translate(text)\n",
    "\n",
    "# text1 = \"à¤¬à¤¢à¤¼à¤¿à¤¯à¤¾ à¤–à¤¾à¤¨à¤¾ à¤¥à¤¾\"\n",
    "# translate(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b59100",
   "metadata": {},
   "source": [
    "### Converting emojies into words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ec455",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_emojis = \"\"\"ğŸ˜„ğŸ˜€ğŸ˜ğŸ˜†ğŸ˜‚ğŸ¤£ğŸ˜ŠğŸ™‚ğŸ˜ğŸ˜‰ğŸ˜ğŸ¥°ğŸ˜˜ğŸ˜‹ğŸ˜›ğŸ˜ğŸ˜œğŸ¤ªğŸ¤©ğŸ¥³ğŸ¥°â¤ï¸ğŸ‘ğŸ‘ŒğŸ¤ŸğŸ”ğŸ•ğŸ£ğŸ°ğŸ¹ğŸ·ğŸº\n",
    "                    ğŸ¦ğŸ¯ğŸ¥ğŸŸğŸ©ğŸ¥¼ğŸ‰ğŸŠğŸ¥³ğŸšğŸ˜ğŸ¥ğŸ¥ ğŸ¥®ğŸ¢ğŸ¡ğŸ§ğŸ¨ğŸ¦ğŸ¥§ğŸ§ğŸ°ğŸ‚ğŸ®ğŸ­ğŸ¬ğŸ«ğŸ¿ğŸ©ğŸªğŸŒ°ğŸ¥œ\n",
    "                    ğŸ¯ğŸ»ğŸ¥‚ğŸ·ğŸ¾ğŸ˜€ğŸ˜ƒğŸ˜„ğŸ˜†ğŸ˜…ğŸ¥²\\ğŸ˜ŠğŸ˜‡ğŸ™‚ğŸ˜€ğŸ˜ƒğŸ˜„ğŸ˜ğŸ˜…ğŸ˜†ğŸ˜‚ğŸ™‚ğŸ˜ŠğŸ¤’ğŸ‘\"\"\"\n",
    "\n",
    "    \n",
    "negative_emojis = \"\"\"ğŸ˜”ğŸ˜ğŸ˜¢ğŸ˜­ğŸ˜¤ğŸ˜ ğŸ˜¡ğŸ¤¬ğŸ˜©ğŸ˜«ğŸ¥ºğŸ˜–ğŸ˜£ğŸ˜ ğŸ˜¤ğŸ˜·ğŸ¤’ğŸ¤•ğŸ˜ğŸ˜¶ğŸ˜’ğŸ˜ğŸ™ğŸ¥¶ğŸ˜¨ğŸ˜±ğŸ˜°ğŸ˜³ğŸ¥µğŸ˜³ğŸ˜µ\n",
    "                     ğŸ¤¯ğŸ¤ğŸ¤®ğŸ¥´ğŸ¤¢ğŸ‘ğŸ˜ˆğŸ‘¿ğŸ’”ğŸ˜©ğŸ˜”ğŸ˜ğŸ˜¢ğŸ˜­\"\"\"\n",
    "\n",
    "\n",
    "# add space between word and emoji\n",
    "def handle_emoji_helper(text):\n",
    "    i = 0\n",
    "    lst = list(text)\n",
    "    for word in text:\n",
    "        if word !=\" \" and (word in positive_emojis or word in negative_emojis):\n",
    "            lst.insert(i,\" \")\n",
    "        i+=1\n",
    "    return \"\".join(lst)\n",
    "\n",
    "def handle_emoji(sentence):\n",
    "    sentence = handle_emoji_helper(sentence)\n",
    "    words = sentence.split()\n",
    "    converted_sentence = []\n",
    "    for word in words:\n",
    "        if word in positive_emojis:\n",
    "            converted_sentence.append(\" good good\") # Don't change ( one word sentences will be removed in\n",
    "        elif word in negative_emojis:                                     #      preprocessing )\n",
    "            converted_sentence.append(\"bad bad\")\n",
    "        else:\n",
    "            converted_sentence.append(word)\n",
    "    return \" \".join(converted_sentence)\n",
    "\n",
    "# # Example usage:\n",
    "# input_sentence = \"ğŸ˜€\"\n",
    "# input_sentence = \"à¤¬à¤¢à¤¼à¤¿à¤¯à¤¾ à¤–à¤¾à¤¨à¤¾ à¤¥à¤¾ğŸ˜€\"\n",
    "# converted = handle_emoji(input_sentence)\n",
    "# print(converted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8271675a",
   "metadata": {},
   "source": [
    "## Apply data cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efc6e63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].apply(clean_text)\n",
    "# df['Text'] = df['Text'].apply(translate)  \n",
    "df['Text'] = df['Text'].apply(handle_emoji)\n",
    "df['Token_Text'] = df['Text'].apply(tokenize_text)\n",
    "df['Token_Text'] = df['Token_Text'].apply(remove_stopwords)\n",
    "df['Token_Text'] = df['Token_Text'].apply(lemmatize_text)\n",
    "df['Token_Text'] = df['Token_Text'].apply(short_remover)\n",
    "df['Token_Text'] = df['Token_Text'].apply(join_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6686a0a6",
   "metadata": {},
   "source": [
    "### Rearrange the column order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb896c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of column names in the desired order\n",
    "desired_order = ['Review_ID', 'Sentence_ID', 'Text','Token_Text', 'Opinion_Target',\n",
    "       'Opinion_Category', 'Opinion_Polarity']\n",
    "\n",
    "# Rearrange the columns\n",
    "df = df[desired_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596bb26e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fe62fe",
   "metadata": {},
   "source": [
    "### Count the number of occurrences of each unique value (Need correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca5e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Opinion_Polarity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738837d4",
   "metadata": {},
   "source": [
    "### Correction ( Deleting all other except ['negative', 'positive','neutral'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fdabf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[~df['Opinion_Polarity'].isin(['negative', 'positive','neutral'])]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f0c0b0",
   "metadata": {},
   "source": [
    "### Correcting Wrong Data in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aee16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.loc[:, 'Opinion_Target'] = filtered_df['Opinion_Category']\n",
    "filtered_df.loc[:, 'Opinion_Category'] = filtered_df['Opinion_Polarity']\n",
    "\n",
    "filtered_df.loc[filtered_df['Sentence_ID'] == \"1300636:2\", 'Opinion_Polarity'] = \"positive\"\n",
    "filtered_df.loc[filtered_df['Sentence_ID'] == \"1352948:1\", 'Opinion_Polarity'] = \"neutral\"\n",
    "filtered_df.loc[filtered_df['Sentence_ID'] == \"1410878:0\", 'Opinion_Polarity'] = \"positive\"\n",
    "filtered_df.loc[filtered_df['Sentence_ID'] == \"1615322:3\", 'Opinion_Polarity'] = \"neutral\"\n",
    "filtered_df.loc[filtered_df['Sentence_ID'] == \"737999:2\", 'Opinion_Polarity'] = \"positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99660a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da5ab0",
   "metadata": {},
   "source": [
    "### Updating main dataset df with filter_df dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a4bb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.update(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5d988c",
   "metadata": {},
   "source": [
    "### Removing Rows where Opinion_Polarity is neutral and where Token_Text is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31590069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Opinion_Polarity'] != 'neutral']\n",
    "df = df[df.Token_Text != \"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59e5249",
   "metadata": {},
   "source": [
    "### count the number of occurrences of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d7b229",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Opinion_Polarity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458999de",
   "metadata": {},
   "source": [
    "### Opinion_Polarity distribution in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006b722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = \"Opinion_Polarity\", data = df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bf16fc",
   "metadata": {},
   "source": [
    "### Adding dummy negative Opinion reviews in dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bcc368",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df.copy()\n",
    "df_negative = df[df['Opinion_Polarity'] == 'negative']\n",
    "df = pd.concat([temp_df, df_negative], ignore_index=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9254a8",
   "metadata": {},
   "source": [
    "### Opinion_Polarity distribution in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12317d78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(x = \"Opinion_Polarity\", data = df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46986036",
   "metadata": {},
   "source": [
    "## Save the preprocessed data to a new CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1886e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"training_dataset/Preprocessed_Restuarant_Dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3182be37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
